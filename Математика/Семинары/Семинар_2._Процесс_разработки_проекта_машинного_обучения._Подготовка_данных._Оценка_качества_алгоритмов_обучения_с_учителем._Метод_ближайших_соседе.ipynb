{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvXuIo2G6tNA"
      },
      "source": [
        "#Семинар 2. Процесс разработки проекта машинного обучения. Подготовка данных. Оценка качества алгоритмов обучения с учителем. Метод ближайших соседей\n",
        "\n",
        "Практическая работа по использованию основных методов подготовки данных для классических задач машинного обучения. Реализация метода ближайших соседей с помощью библиотеки numpy.    \n",
        "\n",
        "\n",
        "# Содержание\n",
        "- [Pandas: описание возможностей](#pandas)\n",
        "- [Структуры данных](#structures)\n",
        "- [Чтение и запись данных](#read_write)\n",
        "- [Индексация и выборка данных](#indexing)\n",
        "- [Обработка данных](#processing)\n",
        "- [Объединение и слияние данных](#merging)\n",
        "- [Визуализация данных](#visualization)\n",
        "- [Работа с временными рядами](#time_series)\n",
        "- [Работа с большими файлами](#big_files)\n",
        "- [Примеры с реальными данными](#real_examples)\n",
        "- [KNN](#KNN)\n",
        "- [KNN для регрессии](#KNN_regression)\n",
        "- [KNN для классификации](#KNN_classification)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hYIRk3hM7QNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fVVQvUc6tNH"
      },
      "source": [
        "## Pandas: описание возможностей  <a class=\"anchor\" id=\"pandas\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y0jZ9SP6tNI"
      },
      "source": [
        "Pandas - это библиотека языка программирования Python для работы с данными, которая предоставляет множество функций для обработки и анализа структурированных данных. Некоторые из основных возможностей pandas включают в себя:\n",
        "\n",
        "1. Структуры данных: Pandas предоставляет две основные структуры данных - Series и DataFrame - для работы с одномерными и двумерными данными соответственно. Эти структуры данных позволяют легко обрабатывать и анализировать различные типы данных.\n",
        "\n",
        "2. Чтение и запись данных: Pandas обеспечивает возможность чтения и записи данных в различных форматах, включая CSV, Excel, SQL, JSON, HTML и другие.\n",
        "\n",
        "3. Индексация и выборка данных: Pandas позволяет выбирать и фильтровать данные с помощью различных методов индексации и срезов, а также выполнять группировку и агрегацию данных.\n",
        "\n",
        "4. Обработка данных: Pandas предоставляет функции для отсутствующих данных, таких как удаление, заполнение, агрегация или замена пропущенных значений.\n",
        "\n",
        "5. Объединение и слияние данных: Pandas позволяет объединять и сливать данные из различных источников, включая объединение по строкам и столбцам, а также соединение таблиц.\n",
        "\n",
        "6. Визуализация данных: Pandas обеспечивает возможность создания различных типов графиков и диаграмм для визуализации данных.\n",
        "\n",
        "7. Работа с временными рядами: Pandas предоставляет функциональность для работы с временными рядами, включая создание временных индексов, агрегацию и ресемплирование данных по времени.\n",
        "\n",
        "8. Работа с большими данными: Pandas поддерживает работу с большими наборами данных, включая возможность чтения и записи данных по частям, использование индексации и выборки для сокращения использования памяти и другие методы оптимизации работы с данными."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-GXwM_86tNK"
      },
      "source": [
        "## Структуры данных  <a class=\"anchor\" id=\"structures\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhp-en7r6tNL"
      },
      "source": [
        "Pandas предоставляет две основные структуры данных - Series и DataFrame.\n",
        "\n",
        "Series - это одномерный массив данных, который можно индексировать и доступ к элементам которого можно осуществлять по индексу. Он может быть разных типов (например, числа, строки, даты и т.д.), но все элементы должны быть одного типа данных. Series удобен для хранения и обработки временных рядов, рядов цен, статистических данных и т.д.\n",
        "\n",
        "DataFrame - это двумерная таблица данных, которая состоит из рядов и колонок. Каждая колонка в DataFrame может содержать данные разных типов (например, числа, строки, даты и т.д.). DataFrame удобен для хранения и обработки больших и сложных наборов данных, таких как таблицы баз данных, файлы Excel, CSV-файлы и т.д.\n",
        "\n",
        "Обе структуры данных Pandas позволяют осуществлять быстрый и удобный доступ к данным, фильтровать данные, выполнять арифметические операции над данными, агрегировать данные, а также визуализировать данные в различных форматах.\n",
        "\n",
        "Series и DataFrame также имеют множество методов и функций для обработки данных, например, для сортировки, фильтрации, замены, удаления и объединения данных. Эти функции и методы делают работу с данными в Pandas быстрой, удобной и эффективной."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKqUG3hN6tNL"
      },
      "source": [
        "### Создание"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSKwNZDY6tNM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Создание Series из списка\n",
        "my_list = [10, 20, 30, 40, 50]\n",
        "s = pd.Series(my_list)\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYzZjwAS6tNQ"
      },
      "outputs": [],
      "source": [
        "# Создание Series из массива NumPy\n",
        "import numpy as np\n",
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "s = pd.Series(arr)\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVLJ3ER-6tNS"
      },
      "outputs": [],
      "source": [
        "# Создание Series из словаря\n",
        "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
        "s = pd.Series(my_dict)\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT6nysd_6tNX"
      },
      "outputs": [],
      "source": [
        "# Создание списка списков\n",
        "data = [[10, 20, 30], [40, 50, 60], [70, 80, 90]]\n",
        "\n",
        "# Создание DataFrame из списка списков\n",
        "df = pd.DataFrame(data, columns=['A', 'B', 'C'])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKmMh6i06tNa"
      },
      "outputs": [],
      "source": [
        "# Создание списка словарей\n",
        "data = [\n",
        "    {'name': 'John', 'age': 30},\n",
        "    {'name': 'Alice', 'age': 25},\n",
        "    {'name': 'Bob', 'age': 40}\n",
        "]\n",
        "\n",
        "# Создание DataFrame из списка словарей\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOjKkgXz6tNc"
      },
      "outputs": [],
      "source": [
        "# Создание словаря списков\n",
        "data = {'A': [10, 20, 30], 'B': [40, 50, 60], 'C': [70, 80, 90]}\n",
        "\n",
        "# Создание DataFrame из словаря списков\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBH9qPY26tNe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Создание массива NumPy\n",
        "data = np.array([[10, 20, 30], [40, 50, 60], [70, 80, 90]])\n",
        "\n",
        "# Создание DataFrame из массива NumPy\n",
        "df = pd.DataFrame(data, columns=['A', 'B', 'C'])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVRwGjg86tNg"
      },
      "source": [
        "## Чтение и запись <a class=\"anchor\" id=\"read_write\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUyBVYBM6tNh"
      },
      "outputs": [],
      "source": [
        "# # Загрузка CSV-файла в DataFrame\n",
        "# df = pd.read_csv('file.csv')\n",
        "\n",
        "# # Вывод содержимого DataFrame\n",
        "# print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdMnhrh66tNi"
      },
      "outputs": [],
      "source": [
        "# # Загрузка Excel-файла в DataFrame\n",
        "# df = pd.read_excel('file.xlsx')\n",
        "\n",
        "# # Вывод содержимого DataFrame\n",
        "# print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24gn_hk36tNk"
      },
      "outputs": [],
      "source": [
        "# import sqlite3\n",
        "\n",
        "# # Создание подключения к базе данных\n",
        "# conn = sqlite3.connect('database.db')\n",
        "\n",
        "# # Загрузка SQL-запроса в DataFrame\n",
        "# df = pd.read_sql_query('SELECT * FROM table', conn)\n",
        "\n",
        "# # Вывод содержимого DataFrame\n",
        "# print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVhZ1aim6tNn"
      },
      "outputs": [],
      "source": [
        "# # Загрузка URL-адреса в DataFrame\n",
        "# df = pd.read_html('https://example.com')[0]\n",
        "\n",
        "# # Вывод содержимого DataFrame\n",
        "# print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2Gpgu816tNo"
      },
      "outputs": [],
      "source": [
        "# # Загрузка текстового файла в объект Series\n",
        "# s = pd.read_csv('file.txt', header=None, squeeze=True)\n",
        "\n",
        "# # Вывод содержимого Series\n",
        "# print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq4Um1kF6tNp"
      },
      "source": [
        "В Pandas есть несколько способов записи данных из объектов Series и DataFrame в файлы. Рассмотрим несколько примеров.\n",
        "В каждом примере мы записываем данные из объектов Series и DataFrame в различные форматы файлов. Каждый пример также показывает, как использовать различные параметры функций для управления процессом записи данных в файлы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phpc-84s6tNq"
      },
      "outputs": [],
      "source": [
        "# Создание DataFrame\n",
        "data = {'name': ['John', 'Jane', 'Sam'],\n",
        "        'age': [25, 30, 35],\n",
        "        'city': ['New York', 'Paris', 'London']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Запись DataFrame в CSV-файл\n",
        "df.to_csv('file.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVg_nP9S6tNr"
      },
      "outputs": [],
      "source": [
        "# Запись DataFrame в Excel-файл\n",
        "# df.to_excel('file.xlsx', index=False)\n",
        "# ModuleNotFoundError: No module named 'openpyxl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFzaIdgy6tNs"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "# Создание подключения к базе данных\n",
        "conn = sqlite3.connect('database.db')\n",
        "\n",
        "# Запись DataFrame в SQL-базу данных\n",
        "df.to_sql('table', conn, if_exists='replace', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHlAtRTq6tNt"
      },
      "outputs": [],
      "source": [
        "# Запись DataFrame в формате JSON\n",
        "df.to_json('file.json', orient='records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2F_0ril6tNu"
      },
      "outputs": [],
      "source": [
        "# Создание объекта Series\n",
        "s = pd.Series([10, 20, 30])\n",
        "\n",
        "# Запись Series в текстовый файл\n",
        "s.to_csv('file.txt', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anF79fk26tNv"
      },
      "source": [
        "## Индексация и выборка данных <a class=\"anchor\" id=\"indexing\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH9zUwS56tNv",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Создание объекта Series\n",
        "s = pd.Series([10, 20, 30, 40, 50])\n",
        "\n",
        "# Индексация по номеру элемента\n",
        "print(s[2])  # выводит 30\n",
        "\n",
        "# Индексация по метке элемента\n",
        "s = pd.Series([10, 20, 30, 40, 50], index=['a', 'b', 'c', 'd', 'e'])\n",
        "print(s[\"a\"])  # выводит 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xHFmhHA6tNw"
      },
      "outputs": [],
      "source": [
        "# Создание DataFrame\n",
        "data = {'name': ['John', 'Jane', 'Sam'],\n",
        "        'age': [25, 30, 35],\n",
        "        'city': ['New York', 'Paris', 'London']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Индексация по метке строки\n",
        "print(df.loc[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReBto5S66tNx"
      },
      "outputs": [],
      "source": [
        "# Индексация по названию столбца\n",
        "print(df['name'])  # выводит столбец 'name'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG1uuIkN6tNy"
      },
      "outputs": [],
      "source": [
        "# Индексация по номеру строки и столбца\n",
        "print(df.iloc[1, 2])  # выводит 'Paris'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5T4WtA_6tN0"
      },
      "outputs": [],
      "source": [
        "# Индексация по метке строки и названию столбца\n",
        "print(df.loc[1, 'city'])  # выводит 'Paris'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc2c1Moh6tN1"
      },
      "outputs": [],
      "source": [
        "# Индексация по условию\n",
        "print(df[df['age'] >= 30])  # выводит строки с возрастом больше 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ5aY3Km6tN2"
      },
      "outputs": [],
      "source": [
        "# Создание DataFrame\n",
        "data = {'name': ['John', 'Jane', 'Sam', 'Alice', 'Bob'],\n",
        "        'age': [25, 30, 35, 40, 45],\n",
        "        'city': ['New York', 'Paris', 'London', 'Paris', 'London']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Индексация DataFrame по условию с использованием оператора &\n",
        "print(df[(df['age'] > 30) & (df['city'] == 'Paris')]) # выводит строки с возрастом больше 30 и городом Paris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R35e3Hn56tN5"
      },
      "outputs": [],
      "source": [
        "# Индексация DataFrame по условию с использованием оператора |\n",
        "print(df[(df['age'] > 30) | (df['city'] == 'Paris')]) # выводит строки с возрастом больше 30 или городом Paris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnGqqYrW6tN6"
      },
      "outputs": [],
      "source": [
        "# Индексация DataFrame по условию с использованием метода query()\n",
        "print(df.query(\"age > 30 and city == 'Paris'\")) # выводит строки с возрастом больше 30 и городом Paris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PimPCVHA6tN7"
      },
      "outputs": [],
      "source": [
        "# Индексация DataFrame по условию с использованием метода loc[]\n",
        "print(df.loc[(df['age'] > 30) & (df['city'] == 'Paris')]) # выводит строки с возрастом больше 30 и городом Paris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38fBJ23x6tN8"
      },
      "outputs": [],
      "source": [
        "# Слайсинг DataFrame по индексу строк и столбцов с использованием метода loc[]\n",
        "print(df.loc[1:3, 'name':'age']) # выводит строки 1-3 и столбцы name и age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLQgYn8b6tN9"
      },
      "outputs": [],
      "source": [
        "# Слайсинг DataFrame по позиции строк и столбцов с использованием метода iloc[]\n",
        "print(df.iloc[1:3, 0:2]) # выводит строки 1-2 и столбцы 0-1 (name и age)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7G9tTTV6tN-"
      },
      "source": [
        "## Обработка данных <a class=\"anchor\" id=\"processing\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJwn4CqP6tN_"
      },
      "source": [
        "Замена значений в столбце на другие значения\n",
        "\n",
        "Можно использовать метод .replace(), передав в него словарь, где ключи - значения,\n",
        "которые нужно заменить, а значения - значения, на которые нужно заменить.\n",
        "Например, заменим значения \"male\" на \"M\" и \"female\" на \"F\" в столбце gender:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq2UcIEF6tN_"
      },
      "outputs": [],
      "source": [
        "# создаем DataFrame\n",
        "df = pd.DataFrame({'name': ['John', 'Mary', 'Peter'],\n",
        "                   'gender': ['male', 'female', 'male']})\n",
        "# заменяем значения в столбце gender\n",
        "df['gender'] = df['gender'].replace({'male': 'M', 'female': 'F'})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj3m2Jc86tOA"
      },
      "source": [
        "Преобразование типа данных столбца\n",
        "Можно использовать метод .astype(), передав в него новый тип данных.\n",
        "Например, преобразуем столбец age из типа object в тип int:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlAN9oXi6tOB"
      },
      "outputs": [],
      "source": [
        "# создаем DataFrame\n",
        "df = pd.DataFrame({'name': ['John', 'Mary', 'Peter'],\n",
        "                   'age': ['25', '30', '35']})\n",
        "# преобразуем тип данных столбца age\n",
        "df['age'] = df['age'].astype(int)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSA8GoEK6tOC"
      },
      "source": [
        "Объединение значений столбцов\n",
        "\n",
        "Можно использовать метод .apply(), передав в него функцию, которая будет объединять значения столбцов.\n",
        "Например, объединим значения столбцов first_name и last_name в новый столбец full_name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl4oCQNV6tOC"
      },
      "outputs": [],
      "source": [
        "# создаем DataFrame\n",
        "df = pd.DataFrame({'first_name': ['John', 'Mary', 'Peter'],\n",
        "                   'last_name': ['Doe', 'Smith', 'Johnson']})\n",
        "# объединяем значения столбцов first_name и last_name\n",
        "df['full_name'] = df.apply(lambda row: row['first_name'] + ' ' + row['last_name'], axis=1)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKWZKq_W6tOD"
      },
      "source": [
        "Удаление строк или столбцов\n",
        "\n",
        "Можно использовать метод .drop(), передав в него индексы строк или столбцов, которые нужно удалить, а также параметр axis=0 для удаления строк или axis=1 для удаления столбцов.\n",
        "Например, удалим столбец age:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g58N1DF66tOE"
      },
      "outputs": [],
      "source": [
        "# создаем DataFrame\n",
        "df = pd.DataFrame({'name': ['John', 'Mary', 'Peter'],\n",
        "                   'age': ['25', '30', '35']})\n",
        "# удаляем столбец age\n",
        "df = df.drop('age', axis=1)\n",
        "df = df.drop(0, axis=0)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYf3LIrN6tOF"
      },
      "source": [
        "Группировка и агрегация данных\n",
        "\n",
        "Можно использовать метод .groupby(), чтобы сгруппировать данные по значениям столбца или нескольких столбцов, а затем применить к группам агрегационную функцию, например, сумму, среднее значение, максимальное значение и т.д.\n",
        "Например, посчитаем средний возраст для каждого пола в DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJnOF1Qh6tOF"
      },
      "outputs": [],
      "source": [
        "# создаем DataFrame\n",
        "df = pd.DataFrame({'name': ['John', 'Mary', 'Peter', 'Mike', 'Sarah'],\n",
        "                   'gender': ['M', 'F', 'M', 'M', 'F'],\n",
        "                   'age': [25, 30, 35, 40, 45]})\n",
        "# считаем средний возраст для каждого пола\n",
        "mean_age_by_gender = df.groupby('gender')['age'].mean()\n",
        "print(mean_age_by_gender)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjPOioSf6tOG"
      },
      "source": [
        "Фильтрация данных по условию\n",
        "\n",
        "Можно использовать условный оператор и метод .loc[], чтобы выбрать строки, удовлетворяющие заданному условию.\n",
        "Например, выберем только те строки, в которых возраст больше 30:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDWxNdJY6tOH"
      },
      "outputs": [],
      "source": [
        "# создаем DataFrame\n",
        "df = pd.DataFrame({'name': ['John', 'Mary', 'Peter', 'Mike', 'Sarah'],\n",
        "                   'age': [25, 30, 35, 40, 45]})\n",
        "# выбираем только строки, у которых возраст больше 30\n",
        "df_filtered = df.loc[df['age'] > 30]\n",
        "print(df_filtered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bnx20_VB45F"
      },
      "source": [
        "## Упражнение <a class=\"anchor\" id=\"processing\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz5C_8BkD5cv"
      },
      "source": [
        "Часть 1. Сделайте копию Dataframe. Зачем это может быть нужно?\n",
        "\n",
        "Часть 2. Есть признак 'age'. Создайте новый признак 'new_age', в котором будут квадраты значений из 'age'. При условии, что величина в 'age' больше 30 строго (не включая). Попробуйте это сделать через lambda функцию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESJ2gDCbB39K"
      },
      "outputs": [],
      "source": [
        "# Ваш код и комментарии\n",
        "\n",
        "# Часть 1\n",
        "\n",
        "\n",
        "# Часть 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LKNbuPv6tOH"
      },
      "source": [
        "## Объединение и слияние данных <a class=\"anchor\" id=\"merging\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smIaFMtP6tOI"
      },
      "source": [
        "Слияние данных - это процесс соединения двух или более наборов данных на основе общих признаков. В pandas это делается с помощью метода merge(). Он принимает на вход два DataFrame и объединяет их по заданным колонкам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-Eoe_D56tOI"
      },
      "outputs": [],
      "source": [
        "# создаем первый DataFrame\n",
        "df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'],\n",
        "                    'value': [1, 2, 3, 4]})\n",
        "# создаем второй DataFrame\n",
        "df2 = pd.DataFrame({'key': ['B', 'D', 'E', 'F'],\n",
        "                    'value': [5, 6, 7, 8]})\n",
        "# объединяем по колонке 'key'\n",
        "merged_df = pd.merge(df1, df2, on='key')\n",
        "print(merged_df)\n",
        "\n",
        "# В результате мы получили новый DataFrame, в котором объединены два исходных DataFrame по значению колонки 'key'.\n",
        "# В данном случае в объединенном DataFrame остались только строки, где значение 'key' было общим для обоих\n",
        "# DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUEaRU9u6tOJ"
      },
      "source": [
        "Объединение данных - это процесс соединения двух или более наборов данных по вертикали (добавление новых строк)\n",
        "или горизонтали (добавление новых колонок). В pandas это делается с помощью методов concat() и join()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YuV4zVJ6tOK"
      },
      "outputs": [],
      "source": [
        "# создаем первый DataFrame\n",
        "df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'],\n",
        "                    'value': [1, 2, 3, 4]})\n",
        "# создаем второй DataFrame\n",
        "df2 = pd.DataFrame({'key': ['E', 'F', 'G', 'H'],\n",
        "                    'value': [5, 6, 7, 8]})\n",
        "# объединяем по вертикали\n",
        "concat_df = pd.concat([df1, df2])\n",
        "print(concat_df)\n",
        "\n",
        "# В данном примере мы объединили два DataFrame по вертикали с помощью метода concat().\n",
        "# В результате мы получили новый DataFrame, состоящий из строк обоих исходных DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbWb95dT6tOL"
      },
      "source": [
        "С помощью метода join() можно объединять DataFrame по колонкам, а не по строкам. Он принимает на вход два DataFrame и объединяет их по заданным колонкам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s09rzlYI6tOM"
      },
      "outputs": [],
      "source": [
        "# создаем первый DataFrame\n",
        "df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'],\n",
        "                    'value1': [1, 2, 3, 4]})\n",
        "# создаем второй DataFrame\n",
        "df2 = pd.DataFrame({'key': ['B', 'D', 'E', 'F'],\n",
        "                    'value2': [5, 6, 7, 8]})\n",
        "# объединяем по колонке 'key'\n",
        "joined_df = df1.set_index('key').join(df2.set_index('key'))\n",
        "print(joined_df)\n",
        "\n",
        "# В данном примере мы объединили два DataFrame по колонке 'key' с помощью метода join().\n",
        "# В результате мы получили новый DataFrame, в котором значения из обоих исходных DataFrame\n",
        "# объединены по значениям колонки 'key'. Если значение отсутствует в одном из DataFrame,\n",
        "# то в объединенном DataFrame оно будет NaN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8WnSNmt6tOM"
      },
      "source": [
        "## Визуализация данных <a class=\"anchor\" id=\"visualization\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcMUzziG6tON"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Создание DataFrame\n",
        "data = {'name': ['John', 'Jane', 'Sam', 'Alice', 'Bob'],\n",
        "        'age': [25, 30, 35, 40, 45],\n",
        "        'city': ['New York', 'Paris', 'London', 'Paris', 'London']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Отображение диаграммы разброса числовых данных DataFrame\n",
        "df.plot.scatter(x='age', y='name')\n",
        "plt.title('Диаграмма разброса возраста и имени')\n",
        "plt.xlabel('Возраст')\n",
        "plt.ylabel('Имя')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxBK2Lvz6tON"
      },
      "outputs": [],
      "source": [
        "# Создание DataFrame с категориальными данными\n",
        "data = {'city': ['New York', 'Paris', 'London'],\n",
        "        'count': [10, 15, 12]}\n",
        "df2 = pd.DataFrame(data)\n",
        "\n",
        "# Отображение столбчатой диаграммы категориальных данных DataFrame\n",
        "df2.plot.bar(x='city', y='count', rot=0)\n",
        "plt.title('Диаграмма количества людей в городах')\n",
        "plt.xlabel('Город')\n",
        "plt.ylabel('Количество людей')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvC5oKOG6tOO"
      },
      "source": [
        "## Работа с временными рядами <a class=\"anchor\" id=\"time_series\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byE7x38p6tOO"
      },
      "outputs": [],
      "source": [
        "# Создание временного ряда с шагом в дни\n",
        "dates = pd.date_range('20220101', periods=365)\n",
        "\n",
        "# Создание DataFrame с временным индексом\n",
        "df = pd.DataFrame({'value': range(365)}, index=dates)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ety8_2Rp6tOP"
      },
      "outputs": [],
      "source": [
        "# Срез по диапазону дат\n",
        "print(df['20220301':'20220501'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPTVjXp46tOQ"
      },
      "outputs": [],
      "source": [
        "# # Агрегирование данных по дням\n",
        "# print(df.resample('D').sum())\n",
        "\n",
        "# # Агрегирование данных по неделям\n",
        "# print(df.resample('W').sum())\n",
        "\n",
        "# Агрегирование данных по месяцам\n",
        "print(df.resample('M').sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX0cgyxp6tOR"
      },
      "source": [
        "Для вычисления скользящего среднего в pandas можно использовать метод rolling(). Например, чтобы вычислить скользящее среднее с окном размером 3 для столбца \"value\" в DataFrame \"df\", можно использовать следующий код:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFaJ1ay56tOS"
      },
      "outputs": [],
      "source": [
        "df['rolling_mean'] = df['value'].rolling(window=3).mean()\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnXuXroY6tOT"
      },
      "source": [
        "Метод rolling() также позволяет задавать другие параметры, такие как минимальное количество наблюдений для вычисления среднего значения (min_periods) и тип окна (window). Например, чтобы использовать взвешенное скользящее среднее с экспоненциальным затуханием, можно задать параметр window следующим образом:\n",
        "```python\n",
        "df['rolling_mean1'] = df['column_name'].rolling(window='expanding').mean()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzRz7BCG6tOU"
      },
      "source": [
        "## Работа с большими файлами <a class=\"anchor\" id=\"big_files\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv1lAMkp6tOU"
      },
      "source": [
        "Pandas предоставляет множество инструментов для работы с большими файлами данных, которые могут не поместиться в оперативную память компьютера.\n",
        "\n",
        "Некоторые из этих инструментов:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JEFFp1O6tOV"
      },
      "source": [
        "Использование параметра chunksize при чтении файла с помощью метода read_csv. Этот параметр позволяет читать файл по кускам определенного размера и выполнять операции с каждым куском данных отдельно. Например, следующий код читает файл \"large_data.csv\" по кускам в 1000 строк и суммирует значения столбца \"value\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JoT-YUj6tOV"
      },
      "outputs": [],
      "source": [
        "chunksize = 1000\n",
        "sum_value = 0\n",
        "\n",
        "# for chunk in pd.read_csv(\"large_data.csv\", chunksize=chunksize):\n",
        "#     sum_value += chunk[\"value\"].sum()\n",
        "\n",
        "# print(\"Total sum of values: \", sum_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHTh1Mav6tOW"
      },
      "source": [
        "Использование функции to_csv для записи данных по частям. В этом случае можно использовать параметры chunksize и mode. Например, следующий код сохраняет файл \"large_data.csv\" по частям в 1000 строк каждая:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFNrBA146tOW"
      },
      "outputs": [],
      "source": [
        "chunksize = 1000\n",
        "i = 0\n",
        "\n",
        "# for chunk in pd.read_csv(\"large_data.csv\", chunksize=chunksize):\n",
        "#     chunk.to_csv(\"large_data_part{}.csv\".format(i), index=False, mode=\"a\")\n",
        "#     i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zR42BRm6tOX"
      },
      "source": [
        "Использование модуля Dask. Dask - это библиотека, которая позволяет обрабатывать большие наборы данных, не помещающиеся в оперативную память, путем распределения задач на несколько вычислительных узлов. Dask имеет сходный с Pandas API, поэтому переход на Dask может быть довольно простым. Например, следующий код считывает файл \"large_data.csv\" с помощью Dask и выводит сумму значений столбца \"value\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYGyJddE6tOY"
      },
      "outputs": [],
      "source": [
        "# import dask.dataframe as dd\n",
        "\n",
        "# df = dd.read_csv(\"large_data.csv\")\n",
        "# sum_value = df[\"value\"].sum().compute()\n",
        "\n",
        "# print(\"Total sum of values: \", sum_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyLwN6i16tOY"
      },
      "source": [
        "Использование модуля Vaex. Vaex - это библиотека для работы с большими наборами данных, которая использует ленивую загрузку и индексирование, чтобы обеспечить быстрое выполнение запросов к данным. Vaex также имеет сходный с Pandas API, но работает намного быстрее для больших наборов данных. Например, следующий код считывает файл \"large_data.csv\" с помощью Vaex и выводит сумму значений столбца \"value\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKPHpEU46tOZ"
      },
      "outputs": [],
      "source": [
        "# import vaex\n",
        "\n",
        "# df = vaex.open(\"large_data.csv\")\n",
        "# sum_value = df.sum(\"value\")\n",
        "\n",
        "# print(\"Total sum of values: \", sum_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bfW-G5w6tOZ"
      },
      "source": [
        "## Примеры с реальными данными <a class=\"anchor\" id=\"real_examples\"></a>\n",
        "\n",
        "https://www.kaggle.com/datasets?search=sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tptluqXH6tOa"
      },
      "source": [
        "## KNN  <a class=\"anchor\" id=\"KNN\"></a>\n",
        "\n",
        "Алгоритм k-ближайших соседей (k-nearest neighbors, KNN) является простым алгоритмом машинного обучения, который используется как для задач классификации, так и для задач регрессии. Он основывается на принципе ближайших соседей, где объекты данных классифицируются или предсказываются на основе ближайших к ним соседей.\n",
        "\n",
        "Для задачи классификации, алгоритм KNN присваивает объекту класс на основе большинства (голосования) классов его k ближайших соседей. Например, если k > 4 и объект имеет k-2 ближайших соседей, принадлежащих к классу \"1\", и только 2 соседей принадлежат к классу \"0\", то объект будет отнесен к классу \"1\".\n",
        "\n",
        "Для задачи регрессии, алгоритм KNN предсказывает числовое значение для объекта на основе среднего (или медианы) значений целевой переменной его k ближайших соседей. Например, если объект имеет k ближайших соседей с целевыми значениями [2, 3, 4, 5, 6], то предсказанное значение будет равно среднему значению 4.\n",
        "\n",
        "Основной параметр алгоритма KNN - это k, который определяет количество ближайших соседей, которые будут участвовать в классификации или предсказании. Выбор оптимального значения k зависит от данных и требует экспериментирования.\n",
        "\n",
        "Алгоритм KNN прост в реализации и понимании, но может быть вычислительно интенсивным для больших наборов данных. Он также может быть чувствителен к масштабированию признаков и может требовать предварительной обработки данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSMuZfeQ6tOb"
      },
      "source": [
        "## KNN для регрессии  <a class=\"anchor\" id=\"KNN_regression\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBaaa7VV6tOc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class KNNRegressor:\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X  # Запоминаем обучающие данные\n",
        "        self.y_train = y  # Запоминаем метки классов\n",
        "\n",
        "    def euclidean_distance(self, x1, x2):\n",
        "        return np.sqrt(np.sum((x1 - x2)**2))  # Вычисляем евклидово расстояние между двумя точками\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = []  # Список для хранения предсказанных значений\n",
        "\n",
        "        for x in X:\n",
        "            distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]  # Вычисляем расстояния до всех точек в обучающих данных\n",
        "            k_indices = np.argsort(distances)[:self.k]  # Получаем индексы k ближайших соседей\n",
        "            k_nearest_targets = [self.y_train[i] for i in k_indices]  # Получаем значения целевых переменных ближайших соседей\n",
        "            y_pred.append(np.mean(k_nearest_targets))  # Добавляем предсказанное значение в список\n",
        "\n",
        "        return np.array(y_pred)  # Преобразуем список в массив и возвращаем его\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqZAIbfz6tOd"
      },
      "outputs": [],
      "source": [
        "# Создание экземпляра класса KNN\n",
        "knn = KNNRegressor(k=3)\n",
        "\n",
        "# Обучение модели\n",
        "X_train = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "y_train = np.array([0, 0.5, 1])\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Новые данные для классификации\n",
        "X_test = np.array([[2, 3], [4, 5]])\n",
        "\n",
        "# Предсказание меток классов\n",
        "y_pred = knn.predict(X_test)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mb6lpFi6tOd"
      },
      "source": [
        "## KNN для классификации  <a class=\"anchor\" id=\"KNN_classification\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pii8Zn0U6tOe"
      },
      "outputs": [],
      "source": [
        "class KNNClassifier:\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X  # Запоминаем обучающие данные\n",
        "        self.y_train = y  # Запоминаем метки классов\n",
        "\n",
        "    def euclidean_distance(self, x1, x2):\n",
        "        return np.sqrt(np.sum((x1 - x2)**2))  # Вычисляем евклидово расстояние между двумя точками\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = []  # Список для хранения предсказанных меток классов\n",
        "\n",
        "        for x in X:\n",
        "            distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]  # Вычисляем расстояния до всех точек в обучающих данных\n",
        "            k_indices = np.argsort(distances)[:self.k]  # Получаем индексы k ближайших соседей\n",
        "            k_nearest_labels = [self.y_train[i] for i in k_indices]  # Получаем метки классов k ближайших соседей\n",
        "            most_common = np.argmax(np.bincount(k_nearest_labels))  # Находим наиболее часто встречающуюся метку класса среди соседей\n",
        "            y_pred.append(most_common)  # Добавляем предсказанную метку класса в список\n",
        "\n",
        "        return np.array(y_pred)  # Преобразуем список в массив и возвращаем его\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abF9llOv6tOf"
      },
      "outputs": [],
      "source": [
        "# Создание экземпляра класса KNN\n",
        "knn = KNNClassifier(k=3)\n",
        "\n",
        "# Обучение модели\n",
        "X_train = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "y_train = np.array([0, 0, 1])\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Новые данные для классификации\n",
        "X_test = np.array([[2, 3], [4, 5]])\n",
        "\n",
        "# Предсказание меток классов\n",
        "y_pred = knn.predict(X_test)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRZl2tX2IrQ9"
      },
      "source": [
        "## Упражнение <a class=\"anchor\" id=\"processing\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TGf0jNjIsW0"
      },
      "source": [
        "Тут всё просто. Есть код. Он должен выводить строчку 'hello from euclidean_distance function :)'. Почему этого не происходит?\n",
        "\n",
        "Это задание на проверку понимая кода. И на проверку понимая текущей среды разработки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BGq4Uu4Nnlr"
      },
      "outputs": [],
      "source": [
        "class KNNClassifier:\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X  # Запоминаем обучающие данные\n",
        "        self.y_train = y  # Запоминаем метки классов\n",
        "\n",
        "    def euclidean_distance(self, x1, x2):\n",
        "        print('hello from euclidean_distance function :)')\n",
        "        return np.sqrt(np.sum((x1 - x2)**2))  # Вычисляем евклидово расстояние между двумя точками\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = []  # Список для хранения предсказанных меток классов\n",
        "\n",
        "        for x in X:\n",
        "            distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]  # Вычисляем расстояния до всех точек в обучающих данных\n",
        "            k_indices = np.argsort(distances)[:self.k]  # Получаем индексы k ближайших соседей\n",
        "            k_nearest_labels = [self.y_train[i] for i in k_indices]  # Получаем метки классов k ближайших соседей\n",
        "            most_common = np.argmax(np.bincount(k_nearest_labels))  # Находим наиболее часто встречающуюся метку класса среди соседей\n",
        "            y_pred.append(most_common)  # Добавляем предсказанную метку класса в список\n",
        "\n",
        "        return np.array(y_pred)  # Преобразуем список в массив и возвращаем его\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNNClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eucEAHEqI-sO"
      },
      "outputs": [],
      "source": [
        "# Создание экземпляра класса KNN\n",
        "knn = KNNClassifier(3)\n",
        "\n",
        "# Обучение модели\n",
        "X_train = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "y_train = np.array([0, 0, 1])\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Новые данные для классификации\n",
        "X_test = np.array([[2, 3], [4, 5]])\n",
        "\n",
        "# Предсказание меток классов\n",
        "y_pred = knn.predict(X_test)\n",
        "print(y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}